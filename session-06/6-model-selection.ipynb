{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Model and hyper parameters choice\n",
    "\n",
    "The dataset used in this notebook is the same used in the last two practice sessions: you can copy-paste into the current directory or download it again from [here](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html).\n",
    "Remember:\n",
    "- you need the kdd.data.gz file\n",
    "- it is a compressed archive, you have to extract it\n",
    "\n",
    "---\n",
    "\n",
    "This session will focus on:\n",
    "- model choice\n",
    "- hyper parameters selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = 'datasets/kddcup.data.corrected'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature names obtained from: http://kdd.ics.uci.edu/databases/kddcup99/kddcup.names\n",
    "header_names = [\n",
    "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', \n",
    "    'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', \n",
    "    'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', \n",
    "    'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', \n",
    "    'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', \n",
    "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', \n",
    "    'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', \n",
    "    'dst_host_srv_rerror_rate', 'attack_type'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(FILENAME, header=None, names=header_names, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>\n",
    "IMPORTANT:\n",
    "    \n",
    "The cell below reduces the size of the dataframe by sampling from it. \n",
    "This is done to work with a smaller amount of data, in case your machine cannot deal with the whole dataset. \n",
    "Try to run the notebook without running this cell but, if you have any problems, come back here, uncomment this line and rerun the whole notebook with less data.\n",
    "</b>\n",
    "\n",
    "If you still have troubles, there is a smaller version available on the same website.\n",
    "The file name is *kddcup.data_10_percent.gz*.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=0.60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info about the dataset (pt. 1)\n",
    "\n",
    "This is the same dataset we used in the past sessions, but it is useful to recap here some information about it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Complete the cell below.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print number of rows, using df.shape\n",
    "print(\"Number of rows =\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Complete the cell below.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print number of features, using the drop and the shape methods\n",
    "print(\"Number of features =\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Type of the features:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_cat_features = (\n",
    "    set(df.drop('attack_type', axis=1).columns) - set(df.drop('attack_type', axis=1).describe().columns)\n",
    ")\n",
    "print(\"There are %d categorical features, and they are:\" % len(set_cat_features))\n",
    "print(set_cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating variables containing indeces of each feature type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = np.array(header_names)\n",
    "\n",
    "nominal_idx = [1, 2, 3]\n",
    "binary_idx = [6, 11, 13, 14, 20, 21]\n",
    "numeric_idx = list(set(range(41)).difference(nominal_idx).difference(binary_idx))\n",
    "\n",
    "nominal_cols = col_names[nominal_idx].tolist()\n",
    "binary_cols = col_names[binary_idx].tolist()\n",
    "numeric_cols = col_names[numeric_idx].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info about the dataset (pt. 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of different 'protocol_type's =\", len(df['protocol_type'].unique()))\n",
    "print(\"Number of occurrences of each protocol_type\")\n",
    "df.groupby('protocol_type').size().reset_index().sort_values(0, ascending=False).rename(columns={0:'cnt'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: What is the effect of <code>.rename(columns={0:'cnt'})</code>, in the cell above?</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "ANS\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Number of different 'flag's =\", len(df['flag'].unique()))\n",
    "print(\"Number of occurrences of each flag\")\n",
    "df.groupby('flag').size().reset_index().sort_values(0, ascending=False).rename(columns={0:'cnt'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Number of different 'service's =\", len(df['service'].unique()))\n",
    "print(\"Number of occurrences of each service\")\n",
    "df.groupby('service').size().reset_index().sort_values(0, ascending=False).rename(columns={0:'cnt'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping each attack type to one category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell modifies the data in the dataframe, if you run it more than once, you might encounter some errors\n",
    "df['attack_type'] = df.apply(lambda r: r['attack_type'][:-1], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file *training_attack_types.txt* maps each of the attacks in the original dataset to 1 category.\n",
    "The file can be found [here](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html), or you can use the same one you used last time.\n",
    "\n",
    "#### IMPORTANT\n",
    "Check that there are no empty lines at the end of the file, otherwise the code below might not work correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = defaultdict(list)\n",
    "category['benign'].append('normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_ATTACK_TYPES_FILENAME = 'datasets/training_attack_types.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAINING_ATTACK_TYPES_FILENAME, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        attack, cat = line.strip().split(' ')\n",
    "        category[cat].append(attack)\n",
    "\n",
    "attack_mapping = {v: k for k in category for v in category[k]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`attack_mapping`, as created above, is a dictionary that maps each attack_type to one category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are %d categories\" % len(set(attack_mapping.values())))\n",
    "print(\"Their names are:\", set(attack_mapping.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the cell that performs the actual mapping\n",
    "df['attack_category'] = df.apply(lambda r: attack_mapping[r['attack_type']], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "This is similar to what was done above. The difference is that here a new column is created (named \"attack_category\"), which contains, for each row, the category of the attack type (<code>r['attack_type']</code> is used as a key to access the dictionary <code>attack_mapping</code>) \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Number of occurrences of each category:\")\n",
    "df.groupby('attack_category').size().reset_index().sort_values(0, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Looking at the results of the previous cell you should realize that you must be very careful with training a 5-class classifier... Why?</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "ANS\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation: dummy variables\n",
    "\n",
    "We have some categorical variables. Thus, we have to converte them to one-hot encoded variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Create a new DataFrame encoding the categorical attributes with one hot encoding.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical feature into dummy variables with one-hot encoding\n",
    "df_one_hot = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation: Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset up into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_one_hot.drop(['attack_category', 'attack_type'], axis=1), \n",
    "    df_one_hot['attack_category'], \n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation: scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell might take a while to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if it crashes, you might want to try rerunning the notebook on less data (see df.sample at the beginning)\n",
    "standard_scaler = StandardScaler().fit(X_train[numeric_cols])\n",
    "\n",
    "X_train[numeric_cols] = standard_scaler.transform(X_train[numeric_cols])\n",
    "X_test[numeric_cols] = standard_scaler.transform(X_test[numeric_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Why is the scaling performed using the X_train variable only?</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "ANS\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation: converting label to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bin = y_train.apply(lambda x: 0 if x is 'benign' else 1)\n",
    "y_test_bin = y_test.apply(lambda x: 0 if x is 'benign' else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REMEMBER: `.apply` applies the `lambda` function within the `()` to each element of the sequence (in this case a Series)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    confusion_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6.1 - BINARY CLASSIFICATION\n",
    "\n",
    "Now you have to train a model for performing binary classification (i.e. detecting whether one entry is malicious or not, without caring about the attack_type).\n",
    "\n",
    "You have to perform cross validation and hyperparameters selections in order to find the best performing model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First example of Cross Validation with GridSearch\n",
    "\n",
    "The following cell performs hyper parameter selection with 5-fold cross validation.\n",
    "The comments inside this cell should provide enough explanation to let you write the code for performing cross validation on different models and different hyper parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>IMPORTANT</b>: you'll probably notice that some of the combination of parameters take a very long time to run. This is normal and it is due to the fact that, for each possible combination of parameters, the model is trained several times (value set in GridSearchCV). Thus, the elapsed time that you had seen in the previous prac session will get much longer.\n",
    "    \n",
    "You might also have some problems due to memory limitations.\n",
    "As mentioned at the beginning of the notebook, try to sample the original DF or, alternatively, use the 10percent dataset (you can download it from the website).\n",
    "    \n",
    "For this session in the classroom, use small lists of parameters and 2-fold or 3-fold cross validation in order to run the code faster.\n",
    "However, while working at home you have to explore larger choices of hyperparameters and use 5-fold cross validation in order to find better performing models.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This line defines the model, in this case a RandomForestClassifier but it could be any classifier (DecisionTreeClassifier, SVC, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this line defines a Pipeline, in this case it is made of only one element and this is what you will need to use for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('clf', classifier)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- parameters of the model in the pipeline can be set using `'__'` separated parameter names. In this case, `'clf__n_estimator'` means that the following list is a list of values for the n_estimators attribute of the clf model. Here, it is the number of trees of the RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'clf__n_estimators': [10, 25, 50],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- performs cross validation for each of the parameters set above. `cv=3` means that I perform 3-fold cross validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchRF = GridSearchCV(pipe, param_grid, iid=False, cv=3, verbose=True)\n",
    "searchRF.fit(X_train, y_train_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- once the training is done, you can show the parameters of the best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(searchRF.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- and you can also retrieve it in order to perform the final test on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedRF = searchRF.best_estimator_.get_params()['clf']\n",
    "trainedRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_RF = trainedRF.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Complete the following cell in order to perform the final evaluation of the model on the test set.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy:\", accuracy_score()) \n",
    "print(\"recall:\", recall_score())\n",
    "print(\"precision:\", precision_score())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another example, this time with a DecisionTreeClassifier\n",
    "\n",
    "It is more convenient to write everything in a unique cell, in order to have everything under control.\n",
    "\n",
    "Here I perform 3-fold cross validation on a DecisionTreeClassifier and explore 3 possible values of `max_depth` and 2 possible values of `max_leaf_nodes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "pipe = Pipeline(steps=[('clf', classifier)])\n",
    "\n",
    "# as you can see, you can set lists of value for all the attributes of the model\n",
    "param_grid = {\n",
    "    'clf__max_leaf_nodes': [10, None],\n",
    "    'clf__max_depth': [2, 5, 10],\n",
    "}\n",
    "\n",
    "searchDT = GridSearchCV(pipe, param_grid, iid=False, cv=3, verbose=True)\n",
    "searchDT.fit(X_train, y_train_bin)\n",
    "\n",
    "print(searchDT.best_params_)\n",
    "\n",
    "trainedDT = searchDT.best_estimator_.get_params()['clf']\n",
    "trainedDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_DT = trainedDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Complete the following cell in order to perform the final evaluation of the model on the test set.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy:\", accuracy_score()) \n",
    "print(\"recall:\", recall_score())\n",
    "print(\"precision:\", precision_score())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now your turn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Use the scikit-learn Pipeline and GridSearchCV in order to find the best model and hyperparameter configuration. Fill the template below.</b>\n",
    "</div>\n",
    "As mentioned above, keep things simple for this practice session otherwise you won't have time to see the results of the training.\n",
    "\n",
    "Possible models to explore:\n",
    "- GaussianNB\n",
    "- DecisionTreeClassifier\n",
    "- RandomForestClassifier\n",
    "- LogisticRegression\n",
    "- ... but **do** feel free to experiment with other ones as well! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ... # feel free to use any models you want\n",
    "\n",
    "pipe = Pipeline(steps=[('clf', classifier)])\n",
    "\n",
    "param_grid = {\n",
    "    ...\n",
    "}\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, iid=False, cv=..., verbose=True)\n",
    "search.fit(X_train, y_train_bin)\n",
    "\n",
    "print(searchDT.best_params_)\n",
    "\n",
    "trained_clf = searchDT...\n",
    "trained_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = trained_clf..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"accuracy:\", ...) \n",
    "print(\"recall:\", ...)\n",
    "print(\"precision:\", ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6.2 - 5-CLASS CLASSIFICATION\n",
    "\n",
    "This last section focuses on performing multiclass classification.\n",
    "Instead of trying to classify each entry as *attack* or *not attack*, we now try to classify it as belonging to one of the following classes:\n",
    "- dos\n",
    "- benign\n",
    "- probe\n",
    "- r2l\n",
    "- u2r\n",
    "\n",
    "Here is an example of model and hyperparameters selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('clf', RandomForestClassifier())])\n",
    "\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [50, 100],\n",
    "    'clf__max_depth': [2, 5, 10],\n",
    "}\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, iid=False, cv=3, verbose=True)\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(search.best_params_)\n",
    "\n",
    "trained_clf = search.best_estimator_.get_params()['clf']\n",
    "trained_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = trained_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy:\", accuracy_score(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_report = classification_report(y_test, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attack_type in set(attack_mapping.values()):\n",
    "    print(attack_type)\n",
    "    print(clf_report[attack_type])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Now it's your turn. Experiment with different models, hyperparameters and try to find the best performing model using cross validation with Pipeline and GridSearchCV. Do not forget to tinker with different features as well: as introduced in the last session, try to remove some features, focus only on some features, etc. in order to improve the classification accuracy.\n",
    "    \n",
    "Remember: *one perfect model* to solve this problem does not exist, but by approaching the problem in the correct way, you can get better and better models.\n",
    "</b>\n",
    "</div>\n",
    "\n",
    "Remember, when performing the final evaluation, to look at all the 5 classes and not only at the overall accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ... # feel free to use any models you want\n",
    "\n",
    "pipe = Pipeline(steps=[('clf', classifier)])\n",
    "\n",
    "param_grid = {\n",
    "    ...\n",
    "}\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, iid=False, cv=..., verbose=True)\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(searchDT.best_params_)\n",
    "\n",
    "trained_clf = searchDT...\n",
    "trained_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = trained_clf..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_report = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "After you finish the notebook, take a look at this link: https://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html\n",
    "\n",
    "In the second Section (\"Face recognition with eigenfaces\"), it presents an example of how to use the techniques that you have seen so far in a more challenging problem (face recognition), which is also very relevant from a security perspective, since face recognition is often used for authentication on hand-held devices.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
